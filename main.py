import os
import re
import base64
import logging
from datetime import datetime, timedelta, timezone
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from telethon.errors import SessionPasswordNeededError
import asyncio

# åŠ è½½ç¯å¢ƒå˜é‡
api_id = int(os.getenv("API_ID"))
api_hash = os.getenv("API_HASH")
session_b64 = os.getenv("SESSION_B64")
group_links = os.getenv("GROUP_LINKS", "").split(",")

session_file_path = "anon.session"

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# èŠ‚ç‚¹æ­£åˆ™è¡¨è¾¾å¼
url_pattern = re.compile(r"(vmess|ss|trojan|vless|tuic|hysteria|hysteria2)://[\S]+")

# èŠ‚ç‚¹è§£æå‡½æ•°ä»¬ï¼ˆæ­¤å¤„ç•¥ï¼Œä¿ç•™åŸå§‹çš„ parse_vmess_node ç­‰ï¼‰
def parse_vmess_node(url, index):
    try:
        data = base64.b64decode(url.split("//", 1)[1] + '==').decode('utf-8')
        return {"type": "vmess", "data": data}
    except:
        return None

# å…¶ä»– parse_xxx_node ç•¥ï¼Œä¿æŒä½ çš„åŸæ ·
# ...

def parse_node(url, index):
    scheme = url.split("://")[0].lower()
    parsers = {
        "vmess": parse_vmess_node,
        "ss": parse_ss_node,
        "trojan": parse_trojan_node,
        "vless": parse_vless_node,
        "tuic": parse_tuic_node,
        "hysteria": parse_hysteria_node,
        "hysteria2": parse_hysteria2_node
    }
    parser = parsers.get(scheme)
    if parser:
        return parser(url, index)
    return None

async def fetch_all_messages_with_rate_limit(client, group_links):
    results = []
    for link in group_links:
        try:
            entity = await client.get_entity(link)
            messages = await client.get_messages(entity, limit=300)
            results.append((link, messages))
            await asyncio.sleep(1.5)
        except Exception as e:
            logging.warning(f"æŠ“å– {link} å¤±è´¥: {e}")
            results.append((link, []))
    return results

def decode_session(session_b64):
    try:
        raw_data = base64.b64decode(session_b64)
        with open(session_file_path, "wb") as f:
            f.write(raw_data)
        return True
    except Exception as e:
        logging.error(f"è§£ç  session å¤±è´¥: {e}")
        return False

async def generate_subscribe_file(nodes):
    content = "\n".join(nodes)
    encoded = base64.b64encode(content.encode()).decode()
    with open("sub", "w") as f:
        f.write(encoded)
    logging.info("å†™å…¥ base64 è®¢é˜…æ–‡ä»¶ sub")

async def main():
    logging.info("ğŸš€ å¼€å§‹æŠ“å– Telegram èŠ‚ç‚¹")
    group_stats = {}
    protocol_stats = {}

    try:
        if not decode_session(session_b64):
            return

        async with TelegramClient(session_file_path, api_id, api_hash) as client:
            now = datetime.now(timezone.utc)
            all_links = set()
            time_ranges = [1, 3, 6, 12, 24]

            for hours in time_ranges:
                logging.info(f"ğŸ“… è®¾ç½®æŠ“å–æ—¶é—´èŒƒå›´: æœ€è¿‘ {hours} å°æ—¶")
                since = now - timedelta(hours=hours)
                group_stats.clear()
                protocol_stats.clear()

                results = await fetch_all_messages_with_rate_limit(client, group_links)
                any_valid_node = False

                for link, messages in results:
                    group_stats[link] = {"success": 0, "failed": 0}

                    for message in messages:
                        if message.date < since:
                            continue
                        found = url_pattern.findall(message.message or '')
                        all_links.update(found)

                        for idx, node in enumerate(found):
                            parsed = parse_node(node, idx)
                            if parsed:
                                group_stats[link]["success"] += 1
                                proto = parsed["type"]
                                protocol_stats[proto] = protocol_stats.get(proto, 0) + 1
                            else:
                                group_stats[link]["failed"] += 1

                if group_stats and any(stats["success"] > 0 for stats in group_stats.values()):
                    any_valid_node = True
                    break

            if not any_valid_node:
                logging.error("æ²¡æœ‰æŠ“å–åˆ°ç¬¦åˆè¦æ±‚çš„èŠ‚ç‚¹ï¼Œè¯·æ£€æŸ¥ç¾¤ç»„é…ç½®æˆ–ç½‘ç»œè¿æ¥ã€‚")
                return

            unique_nodes = list(set(all_links))
            await generate_subscribe_file(unique_nodes)
            logging.info(f"ğŸ’¾ ä¿å­˜èŠ‚ç‚¹é…ç½®å®Œæˆï¼ŒèŠ‚ç‚¹æ•°ï¼š{len(unique_nodes)}")

            logging.info("ğŸ“Š ç¾¤ç»„æŠ“å–ç»Ÿè®¡:")
            for group_link, stats in group_stats.items():
                logging.info(f"{group_link}: æˆåŠŸ {stats['success']}ï¼Œå¤±è´¥ {stats['failed']}")

            logging.info("ğŸ“¦ åè®®ç»Ÿè®¡:")
            for proto, count in protocol_stats.items():
                logging.info(f"{proto}: {count}")

    except Exception as e:
        logging.error(f"ğŸ›‘ æ‰§è¡Œå¤±è´¥: {e}")

    finally:
        if os.path.exists(session_file_path):
            os.remove(session_file_path)
            logging.info("ğŸ§¹ å·²æ¸…ç† session æ–‡ä»¶")

if __name__ == "__main__":
    asyncio.run(main())
