import os
import base64
import logging
import json
import re  # Ensure re module is imported for regular expressions
import asyncio
from datetime import datetime, timedelta, timezone
from telethon import TelegramClient
from telethon.tl.functions.messages import GetHistoryRequest

# ========== é…ç½® ==========
api_id_str = os.getenv("API_ID")
api_hash = os.getenv("API_HASH")
session_b64 = os.getenv("SESSION_B64")

if not all([api_id_str, api_hash, session_b64]):
    raise ValueError("âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼šAPI_IDã€API_HASH æˆ– SESSION_B64")

api_id = int(api_id_str)

# Decode SESSION_B64 to get the actual session binary data
session_file_path = "session.session"
with open(session_file_path, "wb") as session_file:
    session_file.write(base64.b64decode(session_b64))

# ========== æ—¥å¿—é…ç½® ==========
logging.basicConfig(level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.FileHandler("log.txt"), logging.StreamHandler()]
)

# ========== å»é‡å’Œæ³¨é‡Šé‡å¤é“¾æ¥çš„å‡½æ•° ==========
def deduplicate_group_links(raw_links):
    seen = set()
    cleaned_links = []
    annotated_links = []

    for link in raw_links:
        if link in seen:
            annotated_links.append(f"# '{link}',  # ğŸš« é‡å¤")
        else:
            seen.add(link)
            cleaned_links.append(link)
            annotated_links.append(f"'{link}',")

    # è¾“å‡ºæ³¨é‡ŠåŒ–çš„å®Œæ•´é“¾æ¥åˆ—è¡¨ï¼ˆæ‰“å°æˆ–ä¿å­˜ï¼‰
    print("# ===== Telegram ç¾¤ç»„é“¾æ¥ï¼ˆè‡ªåŠ¨æ ‡æ³¨é‡å¤ï¼‰ =====")
    for line in annotated_links:
        print(line)

    logging.info(f"[æ ¡éªŒ] ç¾¤ç»„é“¾æ¥å”¯ä¸€æ•°: {len(cleaned_links)}")
    return cleaned_links

# ========== è§£æèŠ‚ç‚¹ ==========
def parse_vmess_node(node, index):
    try:
        raw = base64.b64decode(node[8:])
        if not raw:
            return None
        conf = json.loads(raw)
        return {
            "name": f"vmess_{index}",
            "type": "vmess",
            "server": conf["add"],
            "port": int(conf["port"]),
            "uuid": conf["id"],
            "alterId": int(conf.get("aid", 0)),
            "cipher": "auto",
            "tls": conf.get("tls", "none") == "tls",
        }
    except Exception as e:
        logging.warning(f"[è§£æå¤±è´¥] vmessï¼š{e}")
        return None

def parse_trojan_node(url, index):
    try:
        raw = url[9:].split("@")
        password = raw[0]
        host_port = raw[1].split("?")[0].split(":")
        if len(host_port) < 2:
            return None
        host, port = host_port[0], int(host_port[1])
        return {
            "name": f"trojan_{index}",
            "type": "trojan",
            "server": host,
            "port": port,
            "password": password,
            "udp": True
        }
    except Exception as e:
        logging.warning(f"[è§£æå¤±è´¥] trojanï¼š{e}")
        return None

def parse_vless_node(url, index):
    try:
        raw = url[8:].split("@")
        uuid = raw[0]
        host_port = raw[1].split("?")[0].split(":")
        if len(host_port) < 2:
            return None
        host, port = host_port[0], int(host_port[1])
        return {
            "name": f"vless_{index}",
            "type": "vless",
            "server": host,
            "port": port,
            "uuid": uuid,
            "encryption": "none",
            "udp": True
        }
    except Exception as e:
        logging.warning(f"[è§£æå¤±è´¥] vlessï¼š{e}")
        return None

def parse_ss_node(url, index):
    try:
        raw = url[5:]
        if "#" in raw:
            raw = raw.split("#")[0]
        if "@" in raw:
            method_password, server_part = raw.split("@")
            method, password = base64.b64decode(method_password + '===').decode().split(":")
        else:
            decoded = base64.b64decode(raw + '===').decode()
            method_password, server_part = decoded.split("@")
            method, password = method_password.split(":")
        server, port = server_part.split(":")
        return {
            "name": f"ss_{index}",
            "type": "ss",
            "server": server,
            "port": int(port),
            "cipher": method,
            "password": password,
            "udp": True
        }
    except Exception as e:
        logging.warning(f"[è§£æå¤±è´¥] ssï¼š{e}")
        return None

# ========== ç”Ÿæˆè®¢é˜…æ–‡ä»¶ ==========
async def generate_subscribe_file(nodes):
    try:
        # ç”Ÿæˆ base64 ç¼–ç è®¢é˜…
        joined_nodes = "\n".join(nodes)
        encoded = base64.b64encode(joined_nodes.encode()).decode()
        with open("sub", "w", encoding="utf-8") as f:
            f.write(encoded)
        logging.info("[å†™å…¥å®Œæˆ] sub")
    except Exception as e:
        logging.warning(f"[é”™è¯¯] ç”Ÿæˆ base64 è®¢é˜…å¤±è´¥ï¼š{e}")

# ========== æŠ“å– Telegram æ¶ˆæ¯ ==========
async def fetch_messages():
    client = TelegramClient(session_file_path, api_id, api_hash)

    try:
        # å¯åŠ¨å®¢æˆ·ç«¯
        await client.start()

        now = datetime.now(timezone.utc)
        since = now - timedelta(hours=6)  # æœ€å¤§æŠ“å–æ—¶é—´èŒƒå›´ï¼ˆä¿®æ”¹ä¸º6å°æ—¶ï¼‰
        all_links = set()

        # å®šä¹‰éœ€è¦æŠ“å–çš„ç¾¤ç»„é“¾æ¥
        raw_group_links = [
            'https://t.me/VPN365R',
            'https://t.me/ConfigsHUB2',
            'https://t.me/free_outline_keys',
            'https://t.me/config_proxy',
            'https://t.me/freenettir',
            'https://t.me/oneclickvpnkeys',
            'https://t.me/entryNET',
            'https://t.me/daily_configs',
            'https://t.me/VPN365R',
            'https://t.me/ConfigsHUB2',
            'https://t.me/free_outline_keys',
            'https://t.me/VPN365R',
            'https://t.me/ConfigsHUB2',
            'https://t.me/free_outline_keys',
        ]

        # è°ƒç”¨å»é‡å‡½æ•°
        group_links = deduplicate_group_links(raw_group_links)

        for link in group_links:
            try:
                entity = await client.get_entity(link)  # ä½¿ç”¨ç¾¤ç»„é“¾æ¥è·å–å®ä½“
                history = await client(GetHistoryRequest(
                    peer=entity,
                    limit=100,
                    offset_date=None,
                    offset_id=0,
                    max_id=0,
                    min_id=0,
                    add_offset=0,
                    hash=0
                ))
                for message in history.messages:
                    found = url_pattern.findall(message.message or '')
                    all_links.update(found)
            except Exception as e:
                logging.warning(f"[é”™è¯¯] è·å– {link} å¤±è´¥ï¼š{e}")

        logging.info(f"[å®Œæˆ] æŠ“å–é“¾æ¥æ•°: {len(all_links)}")
        return list(all_links)
    except Exception as e:
        logging.error(f"ç™»å½•å¤±è´¥: {e}")
        return []

# ========== ä¸»å‡½æ•° ==========
async def main():
    logging.info("[å¯åŠ¨] å¼€å§‹æŠ“å– Telegram èŠ‚ç‚¹")
    raw_nodes = await fetch_messages()
    unique_nodes = list(set(raw_nodes))

    # ä»…ç”Ÿæˆ sub æ–‡ä»¶
    await generate_subscribe_file(unique_nodes)

    logging.info(f"[å®Œæˆ] ä¿å­˜èŠ‚ç‚¹é…ç½®ï¼ŒèŠ‚ç‚¹æ•°ï¼š{len(unique_nodes)}")

if __name__ == "__main__":
    asyncio.run(main())
