import os
import base64
import logging
import json
import re
import asyncio
import random
from datetime import datetime, timedelta, timezone
from telethon import TelegramClient
from telethon.tl.functions.messages import GetHistoryRequest

# ========== é…ç½® ==========
api_id_str = os.getenv("API_ID")
api_hash = os.getenv("API_HASH")
session_b64 = os.getenv("SESSION_B64")

if not all([api_id_str, api_hash, session_b64]):
    raise ValueError("âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼šAPI_IDã€API_HASH æˆ– SESSION_B64")

api_id = int(api_id_str)

# Decode SESSION_B64 to get the actual session binary data
session_file_path = "session.session"
with open(session_file_path, "wb") as session_file:
    session_file.write(base64.b64decode(session_b64))

# ========== æ—¥å¿—é…ç½® ==========
logging.basicConfig(level=logging.INFO,
    format='%(asctime)s - %(message)s',
    handlers=[logging.FileHandler("log.txt"), logging.StreamHandler()]
)

# åŒ¹é…é“¾æ¥çš„æ­£åˆ™è¡¨è¾¾å¼
url_pattern = re.compile(r'(vmess://[^\s]+|ss://[^\s]+|trojan://[^\s]+|vless://[^\s]+|tuic://[^\s]+|hysteria://[^\s]+|hysteria2://[^\s]+)', re.IGNORECASE)

# ========== è§£æèŠ‚ç‚¹ ==========
def parse_node(url, index, node_type):
    try:
        if node_type == 'vmess':
            raw = base64.b64decode(url[8:])
            conf = json.loads(raw)
            return {"name": f"vmess_{index}", "type": "vmess", "server": conf["add"], "port": int(conf["port"]), "uuid": conf["id"], "alterId": int(conf.get("aid", 0)), "cipher": "auto", "tls": conf.get("tls", "none") == "tls"}
        elif node_type == 'trojan':
            raw = url[9:].split("@")
            password, host_port = raw[0], raw[1].split(":")
            return {"name": f"trojan_{index}", "type": "trojan", "server": host_port[0], "port": int(host_port[1]), "password": password, "udp": True}
        elif node_type == 'vless':
            raw = url[8:].split("@")
            uuid, host_port = raw[0], raw[1].split(":")
            return {"name": f"vless_{index}", "type": "vless", "server": host_port[0], "port": int(host_port[1]), "uuid": uuid, "encryption": "none", "udp": True}
        elif node_type == 'ss':
            raw = base64.b64decode(url[5:] + '===').decode()
            method, password, server_port = raw.split(":")[0], raw.split(":")[1], raw.split("@")[1]
            return {"name": f"ss_{index}", "type": "ss", "server": server_port.split(":")[0], "port": int(server_port.split(":")[1]), "cipher": method, "password": password, "udp": True}
        elif node_type == 'tuic':
            raw = url[6:].split("@")
            password, host_port = raw[0], raw[1].split(":")
            return {"name": f"tuic_{index}", "type": "tuic", "server": host_port[0], "port": int(host_port[1]), "password": password, "udp": True}
        elif node_type == 'hysteria':
            raw = url[10:].split("@")
            password, host_port = raw[0], raw[1].split(":")
            return {"name": f"hysteria_{index}", "type": "hysteria", "server": host_port[0], "port": int(host_port[1]), "password": password, "udp": True}
        elif node_type == 'hysteria2':
            raw = url[11:].split("@")
            password, host_port = raw[0], raw[1].split(":")
            return {"name": f"hysteria2_{index}", "type": "hysteria2", "server": host_port[0], "port": int(host_port[1]), "password": password, "udp": True}
    except Exception as e:
        logging.debug(f"è§£æ {node_type} å¤±è´¥: {e}")
        return None

# ========== ä»æ–‡ä»¶ä¸­è§£æèŠ‚ç‚¹ ==========
def parse_nodes_from_file(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            found_urls = url_pattern.findall(content)
            return found_urls
    except Exception as e:
        logging.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return []

# ========== æŠ“å– Telegram æ¶ˆæ¯ ==========
async def fetch_messages_for_group(client, link, since):
    try:
        entity = await client.get_entity(link)
        history = await client(GetHistoryRequest(
            peer=entity,
            limit=100,
            offset_date=None,
            offset_id=0,
            max_id=0,
            min_id=0,
            add_offset=0,
            hash=0
        ))
        messages = [msg.message for msg in history.messages if msg.date >= since]
        return link, messages
    except Exception as e:
        logging.error(f"æŠ“å– {link} æ¶ˆæ¯å¤±è´¥: {e}")
        return link, []

async def fetch_all_messages(client, group_links, since):
    tasks = [fetch_messages_for_group(client, link, since) for link in group_links]
    results = await asyncio.gather(*tasks)
    all_links = set()
    for link, messages in results:
        for message in messages:
            found = url_pattern.findall(message)
            all_links.update(found)
    return all_links

# ========== ä¸»å‡½æ•° ==========
async def main():
    logging.info("ğŸš€ å¼€å§‹æŠ“å– Telegram èŠ‚ç‚¹")
    
    client = TelegramClient(session_file_path, api_id, api_hash)
    
    group_links = [
        'https://t.me/ConfigsHUB2',
    'https://t.me/config_proxy',
    'https://t.me/free_outline_keys',
    'https://t.me/freenettir',
    'https://t.me/v2ray_configs_pool',
    'https://t.me/VPN365R',
    'https://t.me/DailyV2RY',
    'https://t.me/Trick_mobil',
    'https://t.me/vpnplusee_free',
    'https://t.me/daily_configs',
    'https://t.me/oneclickvpnkeys',
    'https://t.me/V2All',
    'https://t.me/Outline_FreeKey',
    'https://t.me/V2ranNG_vpn',
    'https://t.me/v2rey_grum',
    'https://t.me/freevpnatm',
    'https://t.me/GetConfigIR',
    'https://t.me/VIPV2rayNGNP',
    'https://t.me/wxgmrjdcc',
    ]
    file_paths = ["path/to/your/file1.txt", "path/to/your/file2.txt"]

    try:
        # å¯åŠ¨å®¢æˆ·ç«¯
        await client.start()

        now = datetime.now(timezone.utc)
        since = now - timedelta(hours=3)

        # æŠ“å– Telegram æ¶ˆæ¯
        all_links = await fetch_all_messages(client, group_links, since)

        # å¦‚æœæ²¡æœ‰æŠ“åˆ°èŠ‚ç‚¹ï¼Œå°è¯•ä»æ–‡ä»¶æå–
        if not all_links:
            logging.info("Telegram æŠ“å–ä¸åˆ°èŠ‚ç‚¹ï¼Œå°è¯•ä»æ–‡ä»¶ä¸­æå–")
            for file_path in file_paths:
                found_in_file = parse_nodes_from_file(file_path)
                all_links.update(found_in_file)

        if not all_links:
            logging.error("æ²¡æœ‰æŠ“å–åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
            return

        logging.info(f"ğŸ”— æŠ“å–å®Œæˆï¼Œå…±æŠ“å– {len(all_links)} ä¸ªèŠ‚ç‚¹")
        unique_nodes = list(set(all_links))

        # ç”Ÿæˆè®¢é˜…æ–‡ä»¶
        await generate_subscribe_file(unique_nodes)

        logging.info(f"ğŸ’¾ ä¿å­˜èŠ‚ç‚¹é…ç½®å®Œæˆï¼ŒèŠ‚ç‚¹æ•°ï¼š{len(unique_nodes)}")

    except Exception as e:
        logging.error(f"ğŸ›‘ ç™»å½•å¤±è´¥: {e}")

# ========== ç”Ÿæˆè®¢é˜…æ–‡ä»¶ ==========
async def generate_subscribe_file(nodes):
    try:
        joined_nodes = "\n".join(nodes)
        encoded = base64.b64encode(joined_nodes.encode()).decode()
        with open("sub", "w", encoding="utf-8") as f:
            f.write(encoded)
        logging.info("ğŸ‰ è®¢é˜…æ–‡ä»¶ç”Ÿæˆå®Œæ¯•")
    except Exception as e:
        logging.error(f"ç”Ÿæˆè®¢é˜…å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
