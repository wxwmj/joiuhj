import os
import base64
import logging
import json
import re
import asyncio
import random
from datetime import datetime, timedelta, timezone
from telethon import TelegramClient
from telethon.tl.functions.messages import GetHistoryRequest
from telethon.tl.types import DocumentAttributeFilename
from telethon.tl.functions.messages import GetMessages

# ========== é…ç½® ==========
api_id_str = os.getenv("API_ID")
api_hash = os.getenv("API_HASH")
session_b64 = os.getenv("SESSION_B64")

if not all([api_id_str, api_hash, session_b64]):
    raise ValueError("âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼šAPI_IDã€API_HASH æˆ– SESSION_B64")

api_id = int(api_id_str)

# Decode SESSION_B64 to get the actual session binary data
session_file_path = "session.session"
with open(session_file_path, "wb") as session_file:
    session_file.write(base64.b64decode(session_b64))

# ========== æ—¥å¿—é…ç½® ==========
logging.basicConfig(level=logging.INFO,
    format='%(asctime)s - %(message)s',
    handlers=[logging.FileHandler("log.txt"), logging.StreamHandler()]
)

# åŸå§‹ç¾¤ç»„é“¾æ¥ï¼ˆå¯å«é‡å¤ï¼‰
raw_group_links = [
    'https://t.me/ConfigsHUB2',
    'https://t.me/config_proxy',
    'https://t.me/free_outline_keys',
    'https://t.me/freenettir',
    'https://t.me/v2ray_configs_pool',
    'https://t.me/VPN365R',
    'https://t.me/DailyV2RY',
    'https://t.me/Trick_mobil',
    'https://t.me/vpnplusee_free',
    'https://t.me/daily_configs',
    'https://t.me/oneclickvpnkeys',
    'https://t.me/V2All',
    'https://t.me/Outline_FreeKey',
    'https://t.me/V2ranNG_vpn',
    'https://t.me/v2rey_grum',
    'https://t.me/freevpnatm',
    'https://t.me/GetConfigIR',
    'https://t.me/VIPV2rayNGNP',
    'https://t.me/wxgmrjdcc',
]

# å»é‡å¤„ç†ï¼Œå¹¶è®°å½•é‡å¤é¡¹
group_links = []
seen = set()
for link in raw_group_links:
    if link not in seen:
        group_links.append(link)
        seen.add(link)
    else:
        logging.warning(f"é‡å¤ç¾¤ç»„é“¾æ¥å·²å¿½ç•¥ï¼š{link}")

# åŒ¹é…é“¾æ¥çš„æ­£åˆ™è¡¨è¾¾å¼
url_pattern = re.compile(r'(vmess://[^\s]+|ss://[^\s]+|trojan://[^\s]+|vless://[^\s]+|tuic://[^\s]+|hysteria://[^\s]+|hysteria2://[^\s]+)', re.IGNORECASE)

# ========== è§£ææ–‡ä»¶å†…å®¹ ==========
async def parse_file_for_nodes(file, link, index):
    try:
        # ä¸‹è½½æ–‡ä»¶
        file_path = await client.download_media(file, file.name)
        logging.info(f"ä¸‹è½½æ–‡ä»¶: {file.name}")

        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            content = f.read()
        
        # ä»æ–‡ä»¶å†…å®¹ä¸­æå–ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹
        nodes = url_pattern.findall(content)
        valid_nodes = []
        for idx, node in enumerate(nodes):
            if parse_vmess_node(node, idx) or parse_trojan_node(node, idx) or parse_vless_node(node, idx) or parse_ss_node(node, idx) or parse_tuic_node(node, idx) or parse_hysteria_node(node, idx) or parse_hysteria2_node(node, idx):
                valid_nodes.append(node)
        
        # è¿”å›ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹
        return valid_nodes
    except Exception as e:
        logging.error(f"å¤„ç†æ–‡ä»¶ {file.name} æ—¶å‡ºé”™: {e}")
        return []

# ========== æŠ“å– Telegram æ¶ˆæ¯ ==========
async def fetch_messages_for_group(client, link):
    try:
        entity = await client.get_entity(link)
        history = await client(GetHistoryRequest(
            peer=entity,
            limit=100,
            offset_date=None,
            offset_id=0,
            max_id=0,
            min_id=0,
            add_offset=0,
            hash=0
        ))

        all_links = set()

        # éå†å†å²æ¶ˆæ¯ï¼ŒæŸ¥æ‰¾æ–‡æœ¬æ–‡ä»¶å¹¶æå–èŠ‚ç‚¹
        for message in history.messages:
            if message.media and isinstance(message.media, DocumentAttributeFilename):
                file = message.media.document
                if file.mime_type.startswith("text/"):  # ä»…å¤„ç†æ–‡æœ¬æ–‡ä»¶
                    logging.info(f"å‘ç°æ–‡æœ¬æ–‡ä»¶: {file}")
                    # è§£ææ–‡ä»¶ä¸­çš„èŠ‚ç‚¹
                    file_nodes = await parse_file_for_nodes(file, link, 0)
                    all_links.update(file_nodes)

            # å¦‚æœæ¶ˆæ¯åŒ…å«èŠ‚ç‚¹é“¾æ¥ï¼Œåˆ™ç›´æ¥æå–
            if message.text:
                found = url_pattern.findall(message.text)
                all_links.update(found)

        return link, all_links

    except Exception as e:
        logging.error(f"æŠ“å– {link} æ¶ˆæ¯å¤±è´¥: {e}")
        return link, []

async def fetch_all_messages_with_rate_limit(client, group_links):
    tasks = [fetch_messages_for_group(client, link) for link in group_links]
    results = await asyncio.gather(*tasks)
    return results

# ========== ä¸»å‡½æ•° ==========
async def main():
    logging.info("ğŸš€ å¼€å§‹æŠ“å– Telegram èŠ‚ç‚¹")
    
    client = TelegramClient(session_file_path, api_id, api_hash)
    
    group_stats = {}  # ç”¨äºç»Ÿè®¡æ¯ä¸ªç¾¤ç»„çš„ç»“æœ

    try:
        # å¯åŠ¨å®¢æˆ·ç«¯
        await client.start()

        now = datetime.now(timezone.utc)
        all_links = set()

        # è®¾ç½®æ—¶é—´èŒƒå›´å¾ªç¯ï¼šä»1å°æ—¶åˆ°24å°æ—¶
        time_ranges = [1, 3, 6, 12, 24]  # æ—¶é—´èŒƒå›´ï¼Œå•ä½ä¸ºå°æ—¶
        for hours in time_ranges:
            logging.info(f"ğŸ“… è®¾ç½®æŠ“å–æ—¶é—´èŒƒå›´: æœ€è¿‘ {hours} å°æ—¶")
            since = now - timedelta(hours=hours)
            group_stats.clear()  # æ¸…é™¤ä¹‹å‰çš„ç»Ÿè®¡æ•°æ®

            # å¹¶å‘æŠ“å–æ¯ä¸ªç¾¤ç»„çš„æ¶ˆæ¯
            results = await fetch_all_messages_with_rate_limit(client, group_links)

            # å¦‚æœæ²¡æœ‰ç¬¦åˆè¦æ±‚çš„èŠ‚ç‚¹ï¼Œè¿›å…¥ä¸‹ä¸€ä¸ªæ—¶é—´èŒƒå›´
            any_valid_node = False

            for link, messages in results:
                group_stats[link] = {"success": 0, "failed": 0}  # åˆå§‹åŒ–æ¯ä¸ªç¾¤ç»„çš„ç»Ÿè®¡

                for message in messages:
                    if message.date < since:
                        continue
                    found = url_pattern.findall(message.message or '')
                    all_links.update(found)

                    # ç»Ÿè®¡æˆåŠŸçš„èŠ‚ç‚¹
                    for idx, node in enumerate(found):
                        if parse_vmess_node(node, idx) or parse_trojan_node(node, idx) or parse_vless_node(node, idx) or parse_ss_node(node, idx) or parse_tuic_node(node, idx) or parse_hysteria_node(node, idx) or parse_hysteria2_node(node, idx):
                            group_stats[link]["success"] += 1
                        else:
                            group_stats[link]["failed"] += 1

            if group_stats and any(stats["success"] > 0 for stats in group_stats.values()):
                any_valid_node = True  # å¦‚æœæœ‰ç¬¦åˆè¦æ±‚çš„èŠ‚ç‚¹ï¼Œåœæ­¢è°ƒæ•´æ—¶é—´èŒƒå›´
                break  # é€€å‡ºå¾ªç¯ï¼ŒæŠ“å–å·²å®Œæˆ

        if not any_valid_node:
            logging.error("æ²¡æœ‰æŠ“å–åˆ°ç¬¦åˆè¦æ±‚çš„èŠ‚ç‚¹ï¼Œè¯·æ£€æŸ¥ç¾¤ç»„é…ç½®æˆ–ç½‘ç»œè¿æ¥ã€‚")
            return  # å¦‚æœæ²¡æœ‰ç¬¦åˆè¦æ±‚çš„èŠ‚ç‚¹ï¼Œåœæ­¢è„šæœ¬æ‰§è¡Œ

        logging.info(f"ğŸ”— æŠ“å–å®Œæˆï¼Œå…±æŠ“å– {len(all_links)} ä¸ªèŠ‚ç‚¹")
        unique_nodes = list(set(all_links))

        # ä»…ç”Ÿæˆ sub æ–‡ä»¶
        await generate_subscribe_file(unique_nodes)

        logging.info(f"ğŸ’¾ ä¿å­˜èŠ‚ç‚¹é…ç½®å®Œæˆï¼ŒèŠ‚ç‚¹æ•°ï¼š{len(unique_nodes)}")

        # è¾“å‡ºç¾¤ç»„ç»Ÿè®¡ä¿¡æ¯
        logging.info("ğŸ“Š æŠ“å–ç»Ÿè®¡:")
        for group_link, stats in group_stats.items():
            logging.info(f"{group_link}: æˆåŠŸ {stats['success']}ï¼Œå¤±è´¥ {stats['failed']}")

    except Exception as e:
        logging.error(f"ğŸ›‘ ç™»å½•å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
